{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fecd49e",
   "metadata": {},
   "source": [
    "# Google Maps Review Summarizer\n",
    "\n",
    "This Python app automates the process of fetching and summarizing Google Maps reviews for any business or location.\n",
    "\n",
    "## Overview\n",
    "The app performs two main tasks:\n",
    "1. **Scrape Reviews** – Uses a web scraping script to extract reviews directly from Google Maps.\n",
    "2. **Summarize Content** – Leverages OpenAI's language models to generate concise, insightful summaries of the collected reviews and analyse the sentiments.\n",
    "\n",
    "## Tech Stack\n",
    "- **Python** – Core language\n",
    "- **Playwright** – For scraping reviews\n",
    "- **OpenAI API** – For natural language summarization\n",
    "- **Jupyter Notebook** – For exploration, testing, and demonstration\n",
    "\n",
    "### Credits\n",
    "The web scraping logic is **inspired by [Antonello Zanini’s blog post](https://blog.apify.com/how-to-scrape-google-reviews/)** on building a Google Reviews scraper. Special thanks for the valuable insights on **structuring and automating the scraping workflow**, which greatly informed the development of this improved scraper.\n",
    "\n",
    "This app, however, uses an **enhanced version of the scraper** that can scroll infinitely to load more reviews until it collects **at least 1,000 reviews**. If only a smaller number of reviews are available, the scraper stops scrolling earlier.\n",
    "\n",
    "**Note:** This project is intended for educational and research purposes. Please ensure compliance with Google’s [Terms of Service](https://policies.google.com/terms) when scraping or using their data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04a4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:source:1: no such file or directory: ../../../.venv/bin/activate\n",
      "Looking in links: /var/folders/n9/bqzhr3vs6rsc6v_m5w8bz3b40000gn/T/tmphu_nxjjc\n",
      "Requirement already satisfied: pip in ./.venv/lib/python3.12/site-packages (25.3)\n",
      "/Users/jaechoi/repos/llm_replyGenix/.venv/bin/pip3\n",
      "Requirement already satisfied: playwright in ./.venv/lib/python3.12/site-packages (1.56.0)\n",
      "Requirement already satisfied: pyee<14,>=13 in ./.venv/lib/python3.12/site-packages (from playwright) (13.0.0)\n",
      "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in ./.venv/lib/python3.12/site-packages (from playwright) (3.2.4)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.12/site-packages (from pyee<14,>=13->playwright) (4.15.0)\n",
      "Collecting openai\n",
      "  Downloading openai-2.7.2-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.12.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.venv/lib/python3.12/site-packages (from openai) (4.15.0)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading openai-2.7.2-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.12.0-cp312-cp312-macosx_11_0_arm64.whl (319 kB)\n",
      "Downloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Installing collected packages: typing-inspection, tqdm, sniffio, pydantic-core, jiter, idna, h11, distro, certifi, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [openai]14/15\u001b[0m [openai]c]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 anyio-4.11.0 certifi-2025.11.12 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jiter-0.12.0 openai-2.7.2 pydantic-2.12.4 pydantic-core-2.41.5 sniffio-1.3.1 tqdm-4.67.1 typing-inspection-0.4.2\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.2.1\n"
     ]
    }
   ],
   "source": [
    "#Activate a virtual environment\n",
    "!source ../../../.venv/bin/activate \n",
    "\n",
    "#Make sure pip is available and up to date inside the venv\n",
    "!python3 -m ensurepip --upgrade\n",
    "\n",
    "#Verify that pip now points to the venv path (should end with /.venv/bin/pip)\n",
    "!which pip3\n",
    "\n",
    "#Install Playwright inside the venv\n",
    "!pip3 install playwright\n",
    "\n",
    "#Download the required browser binaries and dependencies\n",
    "!python3 -m playwright install\n",
    "\n",
    "# the following not not needed\n",
    "\n",
    "# Install the dotenv package\n",
    "# !pip3 install python-dotenv\n",
    "\n",
    "# Install the openai package\n",
    "# !pip3 install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c794cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "from IPython.display import Markdown, display\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "317af2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f142c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scroll_reviews_panel(page, max_scrolls=50, max_reviews=10):\n",
    "    \"\"\"\n",
    "    Scrolls through the reviews panel to lazy load all reviews.\n",
    "    \n",
    "    Args:\n",
    "        page: Playwright page object\n",
    "        max_scrolls: Maximum number of scroll attempts to prevent infinite loops\n",
    "    \n",
    "    Returns:\n",
    "        Number of reviews loaded\n",
    "    \"\"\"\n",
    "    # Find the scrollable reviews container\n",
    "    # Google Maps reviews are in a specific scrollable div\n",
    "    scrollable_div = page.locator('div[role=\"main\"] div[jslog$=\"mutable:true;\"]').first\n",
    "    \n",
    "    previous_review_count = 0\n",
    "    scroll_attempts = 0\n",
    "    no_change_count = 0\n",
    "\n",
    "    print(\"Starting to scroll and load reviews...\")\n",
    "    \n",
    "    while scroll_attempts < max_scrolls:\n",
    "        # Get current count of reviews\n",
    "        review_elements = page.locator(\"div[data-review-id][jsaction]\")\n",
    "        current_review_count = await review_elements.count()\n",
    "        \n",
    "        #if we have loaded max_reviews, we will stop scrolling\n",
    "        if current_review_count >= max_reviews:\n",
    "            break\n",
    "\n",
    "        print(f\"Scroll attempt {scroll_attempts + 1}: Found {current_review_count} reviews\")\n",
    "        \n",
    "        # Scroll to the bottom of the reviews panel\n",
    "        await scrollable_div.evaluate(\"\"\"\n",
    "            (element) => {\n",
    "                element.scrollTo(0, element.scrollHeight + 100);\n",
    "            }\n",
    "        \"\"\")\n",
    "        \n",
    "        # Wait for potential new content to load\n",
    "        await asyncio.sleep(2)\n",
    "        \n",
    "        # Check if new reviews were loaded\n",
    "        if current_review_count == previous_review_count:\n",
    "            no_change_count += 1\n",
    "            # If count hasn't changed for 3 consecutive scrolls, we've likely reached the end\n",
    "            if no_change_count >= 3:\n",
    "                print(f\"No new reviews loaded after {no_change_count} attempts. Finished loading.\")\n",
    "                break\n",
    "        else:\n",
    "            no_change_count = 0\n",
    "        \n",
    "        previous_review_count = current_review_count\n",
    "        scroll_attempts += 1\n",
    "    \n",
    "    final_count = await review_elements.count()\n",
    "    print(f\"Finished scrolling. Total reviews loaded: {final_count}\")\n",
    "    return final_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7f67b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_google_reviews(url):\n",
    "    # Where to store the scraped data\n",
    "    reviews = []\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "         # Initialize a new Playwright instance\n",
    "        browser = await p.chromium.launch(\n",
    "            headless=True  # Set to False if you want to see the browser in action\n",
    "        )\n",
    "        context = await browser.new_context()\n",
    "        page = await context.new_page()\n",
    "\n",
    "        # The URL of the Google Maps reviews page\n",
    "\n",
    "        # Navigate to the target Google Maps page\n",
    "        print(\"Navigating to Google Maps page...\")\n",
    "        await page.goto(url)\n",
    "\n",
    "        # Wait for initial reviews to load\n",
    "        print(\"Waiting for initial reviews to load...\")\n",
    "        review_html_elements = page.locator(\"div[data-review-id][jsaction]\")\n",
    "        await review_html_elements.first.wait_for(state=\"visible\", timeout=10000)\n",
    "        \n",
    "        # Scroll through the reviews panel to lazy load all reviews\n",
    "        total_reviews = await scroll_reviews_panel(page, max_scrolls=100)\n",
    "        \n",
    "        print(f\"\\nStarting to scrape {total_reviews} reviews...\")\n",
    "\n",
    "        # Get all review elements after scrolling\n",
    "        review_html_elements = page.locator(\"div[data-review-id][jsaction]\")\n",
    "        all_reviews = await review_html_elements.all()\n",
    "        \n",
    "        # Iterate over the elements and scrape data from each of them\n",
    "        for idx, review_html_element in enumerate(all_reviews, 1):\n",
    "            try:\n",
    "                # Scraping logic\n",
    "\n",
    "                stars_element = review_html_element.locator(\"[aria-label*=\\\"star\\\"]\")\n",
    "                stars_label = await stars_element.get_attribute(\"aria-label\")\n",
    "\n",
    "                # Extract the review score from the stars label\n",
    "                stars = None\n",
    "                for i in range(1, 6):\n",
    "                    if stars_label and str(i) in stars_label:\n",
    "                        stars = i\n",
    "                        break\n",
    "\n",
    "                # Get the next sibling of the previous element with an XPath expression\n",
    "                time_sibling = stars_element.locator(\"xpath=following-sibling::span\")\n",
    "                time = await time_sibling.text_content()\n",
    "\n",
    "                # Select the \"More\" button and if it is present, click it\n",
    "                more_element = review_html_element.locator(\"button[aria-label=\\\"See more\\\"]\").first\n",
    "                if await more_element.is_visible():\n",
    "                    await more_element.click()\n",
    "                    await asyncio.sleep(0.3)  # Brief wait for text expansion\n",
    "\n",
    "                text_element = review_html_element.locator(\"div[tabindex=\\\"-1\\\"][id][lang]\")\n",
    "                text = await text_element.text_content()\n",
    "\n",
    "                reviews.append(str(stars) + \" Stars: \\n\" +\"Reviewed On:\" + time + \"\\n\"+ text)\n",
    "                \n",
    "                if idx % 10 == 0:\n",
    "                    print(f\"Scraped {idx}/{total_reviews} reviews...\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping review {idx}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        print(f\"\\nSuccessfully scraped {len(reviews)} reviews!\")\n",
    "\n",
    "        # Close the browser and release its resources\n",
    "        await browser.close()\n",
    "\n",
    "        return \"\\n\".join(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc3772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url = \"https://www.google.com/maps/place/Costco+Wholesale/@33.0355379,-96.8624758,14.29z/data=!4m8!3m7!1s0x864c23810890f0df:0xf9f33301a96d2ff4!8m2!3d33.0238859!4d-96.8314151!9m1!1b1!16s%2Fg%2F1tj58551?entry=ttu&g_ep=EgoyMDI1MTEwOS4wIKXMDSoASAFQAw%3D%3D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d685b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_google_reviews(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb160d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert assistnat that respond to google reviews,\n",
    "and provide a detailed respond to given reviews.\n",
    "Respond in markdonw. Do not wrap the markdown in a code block - respond just with the markdown.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fb67fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our user prompt\n",
    "\n",
    "user_prompt_prefix = \"\"\"\n",
    "Here are the reviews of a google map location/business.\n",
    "Provide a detailed respond of the reviews and the sentiment of the reviews.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d710972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_message(reviews):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_prefix + reviews}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb51f436",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def respond_to_reviews(url):\n",
    "    openai = OpenAI()\n",
    "    reviews = await scrape_google_reviews(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-5-nano\",\n",
    "        messages = prepare_message(reviews)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f09e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def display_responses(url):\n",
    "    responds = await respond_to_reviews(url)\n",
    "    display(Markdown(responds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca7995c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to Google Maps page...\n",
      "Waiting for initial reviews to load...\n",
      "Starting to scroll and load reviews...\n",
      "Scroll attempt 1: Found 8 reviews\n",
      "Finished scrolling. Total reviews loaded: 18\n",
      "\n",
      "Starting to scrape 18 reviews...\n",
      "Scraped 10/18 reviews...\n",
      "\n",
      "Successfully scraped 18 reviews!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Summary of reviews and overall sentiment**\n",
       "\n",
       "- Overall tone: The collection is broadly positive, with a strong leaning toward 5-star experiences. There are a few negative reviews (1–2 stars) that highlight specific issues, mainly around customer service interactions, checkout experience, and a couple of service bottlenecks.\n",
       "\n",
       "- Positive themes (recurrent across many reviews):\n",
       "  - Good value and prices, especially for items like hearing aids, rotisserie chicken, and bakery items.\n",
       "  - Helpful, friendly staff in several departments (e.g., Maddie in service, Raven and Rico in Optical, Maya in the store).\n",
       "  - Clean, organized store environment and a generally good shopping experience.\n",
       "  - Positive experiences with specific services (eye wear adjustments, cake design, car keys support, gas station convenience).\n",
       "  - Consistent praise for staff going above and beyond and for quick, efficient checkout in many instances.\n",
       "\n",
       "- Negative themes (less frequent, but notable):\n",
       "  - Rude or dismissive behavior from a small number of associates, particularly at checkout.\n",
       "  - Aggressive membership enforcement and sometimes unnecessary gatekeeping (e.g., being told to move or not allowed to certain areas).\n",
       "  - Frustration with self-checkout changes and the perception that service quality is diminishing as a result.\n",
       "  - Isolated complaints about Tire Center experiences and heat/discomfort while waiting, plus perceived bias or discrimination.\n",
       "  - A few operational/booking notes (gas station construction, large weekend crowds, occasional delays).\n",
       "\n",
       "- Notable reviews to watch for sentiment:\n",
       "  - 5-star: Maddie’s service, Raven & Rico in Optical, Martha in bakery, and the hearing aid pricing/adjustment experiences.\n",
       "  - 4-star: A long-standing, generally positive Costco experience with some friction due to staff interactions.\n",
       "  - 1–2 star: Specific incidents of rude staff, discriminatory-feeling treatment, or dissatisfaction with checkout/self-checkout structure and customer service.\n",
       "\n",
       "- Quick takeaway:\n",
       "  - If you value Costco for price, breadth of products, and many staff-driven positive experiences, this location tends to deliver.\n",
       "  - There are recurring cautions about occasional poor interactions with some staff, stricter membership enforcement, and some process changes that affect the checkout/assistance experience.\n",
       "\n",
       "If you want, I can categorize the reviews by theme (pricing, staff behavior, checkout experience, services like Optical/Hearing Aids, etc.) or provide a one-sentence sentiment score per review."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = \"https://www.google.com/maps/place/Costco+Wholesale/@33.0355379,-96.8624758,14.29z/data=!4m8!3m7!1s0x864c23810890f0df:0xf9f33301a96d2ff4!8m2!3d33.0238859!4d-96.8314151!9m1!1b1!16s%2Fg%2F1tj58551?entry=ttu&g_ep=EgoyMDI1MTEwOS4wIKXMDSoASAFQAw%3D%3D\"\n",
    "await display_summary(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17163bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
